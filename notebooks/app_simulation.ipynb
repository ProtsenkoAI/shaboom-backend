{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451c0b30-6296-462b-9701-2aadf4b83640",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* pitch detection rip out non-voice\n",
    "\n",
    "### Metric candidates:\n",
    "* absolute error between target and voiced pitch (at every moment)\n",
    "* Raw Pitch Accuracy (for whole song)\n",
    "* proportion f1 for voicing/ silence periods (later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89dd8fd2-1d89-407f-a42a-ab916f704faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n",
      "2021-09-26 10:32:42.437907: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-26 10:32:42.437954: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import IPython.display as ipd\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import demucs\n",
    "import demucs.utils\n",
    "import demucs.separate\n",
    "import demucs.pretrained\n",
    "\n",
    "from resampy import resample\n",
    "import playsound\n",
    "import sounddevice as sd\n",
    "\n",
    "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPool2D, Dropout, Permute, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7351126-c92c-4f70-92a8-30da30738c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.use(\"Qt5Agg\")\n",
    "\n",
    "MODEL_SR = 16000\n",
    "BLOCK_SIZE = 1024\n",
    "N_CHANNELS = 2\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "PITCH_MODEL_SR = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80859dd-9ba1-44a0-84e7-fb0c6264c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocals(mix_pth, model, shifts: int = 1, splits: int=1, overlap: float = 0.25):\n",
    "    loaded_mix = demucs.separate.load_track(mix_pth, DEVICE, N_CHANNELS, model.samplerate)\n",
    "    ref = loaded_mix.mean(0)\n",
    "    normalized_mix = (loaded_mix - ref.mean()) / ref.std()\n",
    "    \n",
    "    all_sources =  demucs.utils.apply_model(model, normalized_mix, shifts=shifts, split=splits,\n",
    "                                    overlap=overlap, progress=True)\n",
    "    return all_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf904210-ed82-4287-8fcc-aa11dd613ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_model = demucs.pretrained.load_pretrained(\"demucs_quantized\")\n",
    "\n",
    "sources_srate = sources_model.samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f951e2ea-f6cd-4aca-a497-14e2731bc671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 240.0/240.0 [01:58<00:00,  2.02seconds/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 210.0/210.0 [01:44<00:00,  2.01seconds/s]\n"
     ]
    }
   ],
   "source": [
    "songs = [\n",
    "    \"../data/samples/Arctic Monkeys-MadSounds.mp3\",\n",
    "#     \"../data/samples/arctic_monkeys_still_take_you_home.mp3\",\n",
    "#     \"../data/samples/arctic-monkeys_mardy-bum.mp3\",\n",
    "    \"../data/samples/radioactive.mp3\",\n",
    "]\n",
    "\n",
    "song_voice_stems = {}\n",
    "\n",
    "for song_pth in songs:\n",
    "    sources = get_vocals(song_pth, sources_model, shifts=1)\n",
    "    vocals_source_idx = sources_model.sources.index(\"vocals\")\n",
    "    song_voice_stems[song_pth] = sources[vocals_source_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56ba9bb-66ce-4733-b19a-4adb20f1d345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sources_model\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4ffc28-fe24-4a0a-b93f-2926026818b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_pitch(signal, pitch_model):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    split_idxs = np.arange(1024, len(signal), 1024)\n",
    "    frames = np.split(signal, split_idxs)\n",
    "\n",
    "    last = frames[-1]\n",
    "        \n",
    "    if len(last) < 1024:\n",
    "        need_to_pad = 1024 - len(last)\n",
    "        right_zeros = need_to_pad // 2\n",
    "        left_zeros = need_to_pad - right_zeros\n",
    "        frames[-1] = np.concatenate([np.zeros((left_zeros, 1)), last, np.zeros((right_zeros, 1))])\n",
    "        \n",
    "    frames = np.concatenate(frames, axis=1)\n",
    "    frames = frames.transpose(1, 0) # had shape (1024, n_samples), converted to (n_samples, 1024)\n",
    "\n",
    "    # normalize each frame -- this is expected by the model\n",
    "    frames -= np.mean(frames, axis=1)[:, np.newaxis]\n",
    "    std = np.std(frames, axis=1)[:, np.newaxis]\n",
    "    std[std == 0] = 1e-10\n",
    "    frames /= std\n",
    "    \n",
    "    \n",
    "    model_preds = pitch_model(frames, training=False)#, workers=-1, use_multiprocessing=True)\n",
    "    model_preds = model_preds.numpy()\n",
    "    \n",
    "    # initially has out shape (length, 360), reducing\n",
    "    too_low_too_high_mask = np.array([True] * 80 + [False] * 140 + [True] * 140)\n",
    "    model_preds[:, too_low_too_high_mask] = 0\n",
    "    \n",
    "#     print(\"time needed\", time.time() - start_time)\n",
    "    batch_pitch = model_preds.argmax(axis=1)\n",
    "    confidence = model_preds.max(axis=1)\n",
    "    \n",
    "    return batch_pitch, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fb14fe-bcc2-4ddb-bd29-0a38a74c28bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_and_load_model(model_capacity, filename):\n",
    "    \"\"\"\n",
    "    Build the CNN model and load the weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_capacity : 'tiny', 'small', 'medium', 'large', or 'full'\n",
    "        String specifying the model capacity, which determines the model's\n",
    "        capacity multiplier to 4 (tiny), 8 (small), 16 (medium), 24 (large),\n",
    "        or 32 (full). 'full' uses the model size specified in the paper,\n",
    "        and the others use a reduced number of filters in each convolutional\n",
    "        layer, resulting in a smaller model that is faster to evaluate at the\n",
    "        cost of slightly reduced pitch estimation accuracy.\n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.keras.models.Model\n",
    "        The pre-trained keras model loaded in memory\n",
    "    \"\"\"\n",
    "\n",
    "    capacity_multiplier = {\n",
    "        'tiny': 4, 'small': 8, 'medium': 16, 'large': 24, 'full': 32\n",
    "    }[model_capacity]\n",
    "\n",
    "    layers = [1, 2, 3, 4, 5, 6]\n",
    "    filters = [n * capacity_multiplier for n in [32, 4, 4, 4, 8, 16]]\n",
    "    widths = [512, 64, 64, 64, 64, 64]\n",
    "    strides = [(4, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n",
    "\n",
    "    x = Input(shape=(1024,), name='input', dtype='float32')\n",
    "    y = Reshape(target_shape=(1024, 1, 1), name='input-reshape')(x)\n",
    "\n",
    "    for l, f, w, s in zip(layers, filters, widths, strides):\n",
    "        y = Conv2D(f, (w, 1), strides=s, padding='same',\n",
    "                   activation='relu', name=\"conv%d\" % l)(y)\n",
    "        y = BatchNormalization(name=\"conv%d-BN\" % l)(y)\n",
    "        y = MaxPool2D(pool_size=(2, 1), strides=None, padding='valid',\n",
    "                      name=\"conv%d-maxpool\" % l)(y)\n",
    "        y = Dropout(0.25, name=\"conv%d-dropout\" % l)(y)\n",
    "\n",
    "    y = Permute((2, 1, 3), name=\"transpose\")(y)\n",
    "    y = Flatten(name=\"flatten\")(y)\n",
    "    y = Dense(360, activation='sigmoid', name=\"classifier\")(y)\n",
    "\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "\n",
    "    model.load_weights(filename)\n",
    "    model.compile('adam', 'binary_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90c29d34-994f-4e65-9a87-4ca7b2e17126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_realtime_pitch_model = build_and_load_model(\"full\", \"../models/model-full.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4f2d5a-b0d0-495d-86f5-41225ac0c253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-26 10:36:36.216090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-26 10:36:36.216118: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-26 10:36:36.216136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gldsn-hw): /proc/driver/nvidia/version does not exist\n",
      "2021-09-26 10:36:36.216417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "pitch_model = build_and_load_model(\"large\", \"../models/model-large.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e79bac9-8751-4c63-9dae-830c0515be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/archive/master.zip\" to /home/arseny/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "vad_model, _ = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac50e60-8ab9-4f25-b860-e21d3e5dbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_voicing_probs(model, wav, num_samples_per_window: int = 4000, num_steps: int = 8, batch_size=200):\n",
    "    \n",
    "    num_samples = num_samples_per_window\n",
    "    assert num_samples % num_steps == 0\n",
    "    step = int(num_samples / num_steps)  # stride / hop\n",
    "    \n",
    "    outs = []\n",
    "    to_concat = []\n",
    "    for i in range(0, len(wav), step):\n",
    "        chunk = wav[i: i+num_samples]\n",
    "        if len(chunk) < num_samples:\n",
    "            chunk = F.pad(chunk, (0, num_samples - len(chunk)))\n",
    "        to_concat.append(chunk.unsqueeze(0))\n",
    "        if len(to_concat) >= batch_size:\n",
    "            chunks = torch.Tensor(torch.cat(to_concat, dim=0))\n",
    "            with torch.no_grad():\n",
    "                out = model(chunks)\n",
    "            outs.append(out)\n",
    "            to_concat = []\n",
    "\n",
    "    outs = torch.cat(outs, dim=0)\n",
    "    return outs[:, 1] # 1 dim is 'neg' and 'pos' classes, so take pos probability\n",
    "\n",
    "def get_voice_activity_mask(wav, model, sr, thresh=0.02):\n",
    "    \n",
    "    transform = torchaudio.transforms.Resample(orig_freq=sr,\n",
    "                                               new_freq=16000)\n",
    "    src_len = len(wav)\n",
    "    wav = transform(wav)\n",
    "    sr = 16000\n",
    "    \n",
    "    probs = get_voicing_probs(model, wav)\n",
    "    wav_prob = np.full(src_len, 0, dtype=np.float32)\n",
    "\n",
    "    step = src_len / len(probs)\n",
    "    start = 0\n",
    "\n",
    "    for prob in probs.flatten().numpy():\n",
    "        wav_prob[round(start): round(start + step)] = prob\n",
    "        start += step\n",
    "    print(\"quantiles\", np.quantile(wav_prob, 0.01), np.quantile(wav_prob, 0.5), np.quantile(wav_prob, 0.95))\n",
    "    winsize = 16000\n",
    "    rolling_mean_wav_prob = np.convolve(wav_prob, np.ones(winsize), 'same') / winsize\n",
    "    return rolling_mean_wav_prob >= thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aee3be1-b9e7-4dd0-98f9-163319f69ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence 0.0019071030616760255 0.6141752004623413 0.9319335460662842\n",
      "pitches_pth ./pitches_Arctic Monkeys-MadSounds.json\n",
      "confidence 0.00029383599758148193 0.21169093251228333 0.9100936949253082\n",
      "pitches_pth ./pitches_radioactive.json\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import json\n",
    "\n",
    "songs_target_pitch = {}\n",
    "\n",
    "for song_pth, vocals in song_voice_stems.items():\n",
    "    mono_vocals = vocals.mean(axis=0, keepdims=False)\n",
    "    # activity_mask = get_voice_activity_mask(mono_vocals, vad_model, 44100, thresh=0.04)\n",
    "    mono_vocals = mono_vocals.numpy()\n",
    "    \n",
    "    # pure_tone = librosa.tone(frequency=5, sr=44100, length=len(mono_vocals))\n",
    "    \n",
    "    # mono_vocals[~activity_mask] = pure_tone[~activity_mask]\n",
    "    \n",
    "    mono_vocals_resampled = resample(mono_vocals, sources_srate, PITCH_MODEL_SR).reshape(-1, 1)\n",
    "    \n",
    "    pitches = []\n",
    "    confidences = []\n",
    "    batch_size = 16\n",
    "    step_size = 1024 * batch_size\n",
    "    for split_idx in range(step_size, len(mono_vocals), step_size):\n",
    "        batch_pitch, batch_confidence = detect_pitch(mono_vocals_resampled[split_idx: split_idx + step_size], pitch_model)\n",
    "        pitches += list(batch_pitch)\n",
    "        confidences += list(batch_confidence)\n",
    "        \n",
    "    pitches = np.array(pitches)\n",
    "    confidences = np.array(confidences)\n",
    "        \n",
    "    print(\"confidence\", np.quantile(confidences, 0.01), np.quantile(confidences, 0.5), np.quantile(confidences, 0.95))\n",
    "    pitches = pitches.astype(np.float32)\n",
    "    pitches[confidences < 0.65] = None\n",
    "    \n",
    "    songs_target_pitch[song_pth] = pitches\n",
    "    \n",
    "    detected_pitches_lst = pitches.flatten().tolist()\n",
    "    pitches_pth = f\"./pitches_{song_pth.split('/')[-1].split('.')[0]}.json\"\n",
    "    print(\"pitches_pth\", pitches_pth)\n",
    "    with open(pitches_pth, \"w\") as f:\n",
    "        json.dump(detected_pitches_lst, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3f0b942-30b1-4402-8455-e7b649773982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 168.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 177.0, 177.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 178.0, 178.0, nan, nan, nan, nan, 178.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 108.0, nan, nan, nan, nan, nan, nan, 133.0, 133.0, 133.0, nan, nan, nan, 132.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 151.0, 153.0, 155.0, 157.0, 156.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 174.0, 175.0, nan, 175.0, nan, 177.0, nan, 176.0, 177.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 178.0, 178.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 178.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 213.0, 213.0, nan, nan, 213.0, nan, 212.0, nan, 192.0, 183.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 119.0, nan, nan, 128.0, nan, 153.0, 152.0, 168.0, nan, nan, nan, nan, nan, 213.0, 212.0, 214.0, 212.0, nan, 203.0, 201.0, 205.0, 195.0, 208.0, nan, nan, nan, nan, nan, nan, nan, 156.0, nan, nan, nan, nan, 198.0, nan, 213.0, nan, nan, nan, nan, 213.0, 209.0, nan, 204.0, 203.0, 203.0, 203.0, 202.0, 204.0, 202.0, 202.0, nan, 203.0, nan, nan, nan, nan, 187.0, 190.0, 188.0, 187.0, 188.0, 187.0, nan, 184.0, 188.0, 188.0, 187.0, 189.0, nan, nan, 191.0, 191.0, 192.0, 192.0, 193.0, 193.0, 189.0, 187.0, 188.0, 190.0, 186.0, 190.0, nan, nan, 169.0, 186.0, 193.0, 192.0, nan, 182.0, 185.0, 188.0, 189.0, 184.0, 181.0, 177.0, 178.0, 178.0, 178.0, 176.0, 181.0, 177.0, 176.0, 179.0, 178.0, 178.0, 178.0, nan, nan, nan, nan, 142.0, nan, nan, nan, 206.0, 211.0, 212.0, 213.0, nan, 213.0, 213.0, 213.0, nan, nan, 203.0, 204.0, 203.0, 204.0, 203.0, 195.0, 210.0, 202.0, nan, nan, nan, nan, nan, 163.0, nan, nan, nan, 173.0, nan, 169.0, nan, nan, nan, 170.0, 168.0, 167.0, 170.0, nan, nan, nan, 164.0, 168.0, 168.0, 167.0, 169.0, nan, nan, 171.0, 168.0, 169.0, nan, nan, nan, nan, 206.0, nan, nan, 175.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 162.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 159.0, nan, nan, nan, nan, nan, 213.0, nan, nan, 214.0, 212.0, 214.0, 213.0, nan, 203.0, 202.0, 203.0, nan, 203.0, 200.0, 210.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 204.0, nan, 213.0, nan, 213.0, nan, nan, nan, 208.0, 203.0, 204.0, 201.0, 203.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, 163.0, 169.0, nan, nan, nan, 190.0, 187.0, nan, nan, 189.0, 184.0, 188.0, 190.0, nan, nan, 188.0, 189.0, 191.0, 193.0, nan, 185.0, nan, nan, nan, 188.0, 188.0, 187.0, 188.0, nan, 187.0, nan, 191.0, 190.0, nan, nan, 180.0, 177.0, nan, nan, 179.0, 176.0, 178.0, 177.0, nan, 182.0, 173.0, 171.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 213.0, nan, nan, nan, nan, 213.0, 212.0, nan, nan, nan, 202.0, 201.0, 203.0, 205.0, 201.0, nan, nan, nan, nan, nan, nan, 168.0, 169.0, 169.0, nan, nan, nan, nan, nan, 167.0, 168.0, nan, nan, nan, 170.0, 168.0, 166.0, 170.0, 168.0, 167.0, 170.0, 166.0, 167.0, 168.0, 167.0, 168.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 140.0, 150.0, 173.0, nan, nan, nan, 178.0, 178.0, 177.0, nan, nan, nan, nan, nan, nan, nan, 178.0, nan, 178.0, nan, nan, 177.0, 183.0, nan, 178.0, nan, nan, nan, nan, nan, 182.0, 177.0, 176.0, nan, nan, nan, 180.0, nan, 176.0, 178.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 212.0, nan, 213.0, 213.0, 212.0, 209.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 180.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 219.0, 212.0, nan, 218.0, 213.0, nan, 203.0, nan, nan, nan, nan, 200.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 203.0, nan, 211.0, nan, nan, 207.0, 203.0, 202.0, 204.0, nan, 208.0, 212.0, 207.0, nan, 184.0, nan, nan, nan, nan, nan, nan, 179.0, 179.0, nan, nan, 179.0, nan, nan, nan, nan, 215.0, 213.0, 212.0, nan, 202.0, nan, nan, nan, 212.0, 213.0, 207.0, 192.0, nan, nan, nan, 177.0, 178.0, nan, 177.0, nan, 166.0, nan, 213.0, nan, nan, nan, nan, nan, 210.0, 213.0, 211.0, nan, 202.0, 201.0, nan, 207.0, 213.0, 211.0, nan, nan, nan, nan, 177.0, 178.0, 177.0, 178.0, 177.0, nan, nan, 180.0, nan, nan, 163.0, nan, nan, nan, 182.0, nan, nan, 179.0, 177.0, nan, nan, nan, nan, nan, 177.0, nan, nan, nan, nan, 192.0, nan, nan, nan, 191.0, nan, 192.0, 192.0, nan, 192.0, nan, nan, nan, nan, 193.0, nan, 193.0, nan, 188.0, 184.0, 177.0, nan, nan, 171.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 202.0, nan, nan, nan, nan, nan, nan, nan, nan, 178.0, 181.0, nan, 177.0, 178.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 219.0, nan, nan, nan, 211.0, 213.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 158.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 192.0, nan, 191.0, nan, nan, nan, 201.0, nan, nan, nan, nan, 179.0, 176.0, 176.0, 178.0, 176.0, nan, nan, nan, nan, nan, nan, nan, 177.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 148.0, 217.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 213.0, 212.0, 213.0, 213.0, nan, 215.0, 211.0, 210.0, nan, nan, nan, nan, nan, nan, 212.0, nan, nan, nan, nan, nan, nan, 209.0, nan, 188.0, 200.0, 205.0, 208.0, 212.0, nan, nan, nan, 202.0, 203.0, 203.0, 203.0, 203.0, 200.0, 203.0, nan, 200.0, 207.0, nan, nan, nan, 199.0, 138.0, nan, nan, 203.0, 209.0, nan, 201.0, 201.0, nan, 213.0, nan, nan, nan, 204.0, 203.0, 202.0, 203.0, 205.0, 200.0, 202.0, 202.0, nan, 207.0, 199.0, 201.0, nan, nan, nan, nan, nan, 190.0, 189.0, nan, nan, 188.0, 188.0, 187.0, 188.0, 187.0, 190.0, nan, 188.0, 187.0, 186.0, 192.0, 193.0, 192.0, nan, nan, nan, nan, 189.0, 186.0, 187.0, 193.0, nan, nan, 190.0, 187.0, 183.0, 178.0, nan, nan, nan, 184.0, nan, nan, nan, 178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 179.0, 177.0, 177.0, 178.0, nan, nan, nan, nan, 153.0, nan, nan, nan, 208.0, 211.0, 212.0, 208.0, 207.0, 209.0, 213.0, 212.0, nan, 190.0, 201.0, nan, 203.0, 202.0, 203.0, nan, nan, 205.0, nan, nan, nan, nan, nan, 157.0, nan, nan, nan, 169.0, 168.0, nan, 140.0, nan, nan, nan, 167.0, 168.0, nan, 168.0, 168.0, 169.0, 167.0, 168.0, 169.0, 168.0, 166.0, 169.0, 164.0, 165.0, 171.0, 163.0, 171.0, nan, 163.0, 173.0, 158.0, 173.0, 175.0, 162.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 162.0, 158.0, nan, nan, nan, nan, nan, nan, nan, 213.0, 212.0, 213.0, 214.0, nan, nan, 203.0, 203.0, 201.0, 204.0, 200.0, nan, 206.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, 200.0, nan, nan, nan, nan, 214.0, nan, 211.0, nan, 206.0, 203.0, 203.0, 200.0, 203.0, 203.0, nan, nan, nan, nan, nan, nan, nan, nan, 167.0, nan, nan, nan, nan, nan, nan, nan, 189.0, 186.0, 187.0, 190.0, nan, nan, nan, 187.0, 191.0, 192.0, 193.0, nan, 189.0, nan, nan, 187.0, 188.0, 188.0, 188.0, 187.0, nan, nan, 185.0, 193.0, 187.0, nan, nan, 179.0, 169.0, nan, nan, 177.0, 177.0, 179.0, 171.0, 182.0, 177.0, 174.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, 132.0, nan, nan, nan, 212.0, nan, nan, nan, 215.0, 212.0, 212.0, nan, nan, nan, 203.0, 200.0, 204.0, 204.0, nan, nan, nan, nan, nan, nan, 167.0, 168.0, 169.0, 168.0, 169.0, nan, nan, 173.0, 167.0, 168.0, 165.0, nan, nan, 175.0, 167.0, 168.0, 168.0, 169.0, 167.0, 168.0, 169.0, 164.0, 169.0, 167.0, 170.0, nan, nan, nan, nan, nan, 171.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, 141.0, nan, 178.0, nan, nan, nan, 178.0, 177.0, 178.0, nan, nan, nan, nan, 143.0, nan, nan, nan, 178.0, nan, nan, nan, 180.0, 183.0, 178.0, 176.0, nan, 174.0, nan, nan, 180.0, 178.0, 176.0, 176.0, nan, nan, nan, nan, nan, 179.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 211.0, 212.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 218.0, nan, nan, nan, 211.0, nan, nan, nan, 201.0, nan, 201.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 209.0, nan, 203.0, nan, nan, 210.0, nan, nan, nan, 202.0, nan, nan, 204.0, nan, nan, 203.0, 188.0, nan, nan, nan, nan, nan, nan, nan, 181.0, nan, nan, nan, nan, nan, nan, nan, nan, 213.0, 213.0, nan, 203.0, 202.0, nan, nan, nan, 213.0, 211.0, 199.0, 184.0, nan, nan, nan, 178.0, 176.0, 174.0, 181.0, nan, nan, nan, 213.0, 195.0, nan, nan, nan, nan, 213.0, 213.0, nan, 202.0, 201.0, nan, nan, 211.0, 213.0, 207.0, nan, 178.0, nan, 173.0, nan, 178.0, 177.0, nan, 178.0, 174.0, 176.0, nan, nan, nan, 162.0, nan, nan, 182.0, 179.0, nan, 181.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 193.0, 192.0, 193.0, nan, 193.0, 195.0, nan, nan, 191.0, 193.0, 192.0, nan, nan, nan, nan, nan, 192.0, 193.0, 192.0, nan, 187.0, 179.0, 173.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 192.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 177.0, 177.0, 180.0, nan, 179.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 218.0, nan, nan, nan, nan, nan, nan, nan, nan, 213.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 193.0, nan, nan, nan, nan, 203.0, nan, 203.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 193.0, nan, nan, nan, nan, 202.0, nan, nan, nan, 178.0, 179.0, nan, nan, 177.0, nan, nan, nan, nan, nan, nan, nan, nan, 175.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 163.0, 161.0, 160.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 219.0, 214.0, nan, nan, nan, 213.0, 213.0, nan, nan, nan, nan, 213.0, 210.0, 184.0, 185.0, 188.0, 193.0, 192.0, 190.0, 193.0, 188.0, 190.0, 190.0, 193.0, nan, 188.0, 193.0, 193.0, 185.0, 189.0, nan, nan, 203.0, 193.0, 188.0, nan, nan, nan, 190.0, 188.0, 187.0, 187.0, 187.0, 188.0, 188.0, 188.0, 187.0, 189.0, 189.0, 183.0, 189.0, 186.0, 188.0, 188.0, 187.0, 188.0, 187.0, 188.0, 189.0, 188.0, 187.0, 189.0, 187.0, 185.0, nan, nan, nan, 178.0, 179.0, 188.0, 188.0, 187.0, 190.0, 186.0, 187.0, 189.0, 186.0, 187.0, 190.0, 187.0, 183.0, 189.0, 191.0, 186.0, 180.0, nan, nan, 178.0, 177.0, 178.0, 176.0, nan, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 179.0, 176.0, 178.0, 179.0, 177.0, 177.0, 178.0, 179.0, 177.0, nan, nan, nan, nan, nan, nan, 131.0, nan, 163.0, 178.0, 184.0, 188.0, 189.0, 190.0, 190.0, 191.0, 192.0, 193.0, 193.0, 193.0, nan, 192.0, 192.0, 192.0, 193.0, 193.0, 192.0, 195.0, 200.0, 198.0, 192.0, nan, 192.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 187.0, 187.0, 188.0, 188.0, 187.0, 189.0, 187.0, 188.0, 187.0, 189.0, 188.0, 187.0, 188.0, 188.0, nan, 188.0, 188.0, nan, nan, nan, nan, 180.0, 183.0, 187.0, 188.0, 187.0, 188.0, 187.0, nan, 185.0, nan, nan, 195.0, 187.0, 181.0, 178.0, 178.0, 177.0, 178.0, 178.0, 178.0, 177.0, nan, 175.0, nan, nan, 179.0, 177.0, 178.0, nan, 178.0, 177.0, 178.0, 178.0, 178.0, 177.0, 178.0, 178.0, 178.0, 177.0, 178.0, 178.0, nan, 177.0, 177.0, 178.0, 176.0, 179.0, 178.0, nan, 178.0, 176.0, 178.0, 179.0, 173.0, 183.0, nan, 178.0, 178.0, nan, nan, 179.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, 177.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 204.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 178.0, nan, 213.0, 212.0, 211.0, nan, nan, nan, nan, nan, 176.0, 179.0, nan, nan, nan, nan, nan, nan, 179.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 217.0, nan, nan, 214.0, 212.0, 204.0, nan, nan, 202.0, 205.0, 200.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 203.0, nan, nan, 209.0, nan, nan, nan, 202.0, nan, nan, 204.0, 203.0, nan, 202.0, 187.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 212.0, 212.0, 203.0, 203.0, 204.0, nan, nan, 211.0, 213.0, 209.0, nan, 183.0, nan, nan, nan, 178.0, nan, 175.0, 182.0, nan, 198.0, nan, nan, nan, 203.0, nan, nan, nan, 213.0, 212.0, nan, 202.0, nan, nan, 204.0, 212.0, 213.0, nan, nan, 177.0, nan, 174.0, nan, 178.0, 178.0, 178.0, 178.0, 174.0, nan, nan, nan, nan, nan, nan, nan, 182.0, 178.0, 173.0, 181.0, nan, nan, nan, nan, nan, nan, nan, nan, 165.0, nan, 193.0, 192.0, nan, nan, 194.0, nan, nan, nan, nan, nan, nan, nan, nan, 192.0, nan, nan, 192.0, nan, 192.0, nan, 186.0, 179.0, 172.0, 182.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 210.0, 203.0, nan, nan, 192.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 176.0, 177.0, 181.0, nan, 179.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 202.0, nan, nan, nan, nan, nan, 204.0, 204.0, 203.0, 202.0, nan, nan, 204.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 204.0, nan, nan, nan, nan, nan, nan, nan, 202.0, nan, nan, nan, nan, nan, 178.0, nan, nan, 177.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 219.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 219.0, nan, nan, nan, nan, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 209.0, 216.0, nan, nan, nan, nan, 213.0, 213.0, 213.0, 212.0, 213.0, 212.0, 214.0, 212.0, 212.0, nan, 212.0, nan, nan, nan, nan, 213.0, 213.0, 213.0, 213.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./pitches_radioactive.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7689469-3fb3-4807-818b-dbd8a36cfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(songs_target_pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ea044-87ea-496f-870a-76cd8edcef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff478c8-79aa-4003-b114-379d97a996ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f17dc3af880>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(detected_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213a6d87-96e5-499f-a624-bf324d190684",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c37747c-5d9d-4d7a-b0ca-612e9cdfc792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del not_realtime_pitch_model\n",
    "# import gc\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "098b2d22-43e8-448b-a507-004d9993e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self, targ_pitch, n_points = 200, user_plotted_points = 60, mae_npoints = 30):\n",
    "        \n",
    "        assert user_plotted_points <= n_points\n",
    "        self.n_points = n_points\n",
    "        self.mae_npoints = mae_npoints\n",
    "        self.user_plotted_points = user_plotted_points\n",
    "        self.n_target_future_points = n_points - user_plotted_points\n",
    "        \n",
    "        self.user_pitch_padding = np.full(self.n_target_future_points, np.nan)\n",
    "        \n",
    "\n",
    "        points = []\n",
    "        passed_detected_pitch = []\n",
    "\n",
    "        self.fig, axes = plt.subplots(ncols=2, figsize=(18, 6))\n",
    "        self.pitch_ax, self.metrics_ax = axes\n",
    "        \n",
    "        self.pitch_ax.set_ylim((60, 300))\n",
    "        self.metrics_ax.set_ylim((0, 100))\n",
    "        self.metrics_ax.set_xlim((0, self.n_points))\n",
    "        print(self.pitch_ax, self.metrics_ax)\n",
    "\n",
    "        # animated=True tells matplotlib to only draw the artist when we\n",
    "        # explicitly request it\n",
    "        self.user_pitch_arr = np.zeros(self.user_plotted_points)\n",
    "        \n",
    "        self.target_past = np.zeros(self.user_plotted_points).astype(np.float32)\n",
    "        self.target_future = targ_pitch[:self.n_target_future_points].astype(np.float32)\n",
    "#         self.target_pitch_arr = np.concatenate([target_past, target_future])\n",
    "        \n",
    "        self.targ_pitch_queue = list(targ_pitch[self.n_target_future_points:])\n",
    "        \n",
    "        \n",
    "        self.mae_arr = np.full(self.n_points, np.nan)\n",
    "        \n",
    "        self.user_pitch_plot = self._create_plot(np.concatenate([self.user_pitch_arr, self.user_pitch_padding]), self.pitch_ax)\n",
    "        # different colors for already passed target and future target\n",
    "        self.target_past_plot = self._create_plot(self.target_past, self.pitch_ax, c=\"red\")\n",
    "        self.target_future_plot = self._create_plot(self.target_future, self.pitch_ax, c=\"orange\", x=range(len(self.target_past), self.n_points))\n",
    "        \n",
    "        self.mae_plot = self._create_plot(self.mae_arr, self.metrics_ax, c=\"red\")\n",
    "        \n",
    "#         (plotted_data,) = self.pitch_ax.plot(range(n_points), [60] * (n_points - 1) + [300], animated=True)\n",
    "#         (plotted_detected,) = ax.plot(range(n_points), [50] + [310] * (n_points - 1), animated=True, c=\"orange\")\n",
    "        plt.show(block=False)\n",
    "        plt.pause(0.1)\n",
    "\n",
    "        self._bg = self.fig.canvas.copy_from_bbox(self.fig.bbox)\n",
    "        # draw the animated artist, this uses a cached renderer\n",
    "        self.axes = {\n",
    "                    \"pitch\": {\"artists\": [], \"ax\": self.pitch_ax},\n",
    "                    \"metrics\": {\"artists\": [], \"ax\": self.metrics_ax}\n",
    "        }\n",
    "        \n",
    "        self.axes[\"pitch\"][\"artists\"] += [self.user_pitch_plot, self.target_past_plot, self.target_future_plot]\n",
    "        self.axes[\"pitch\"][\"artists\"] += [self.mae_plot]\n",
    "        \n",
    "        self._redraw_plot()\n",
    "        \n",
    "    def _create_plot(self, data, ax, c=\"blue\", x=None):\n",
    "        if x is None:\n",
    "            x = range(len(data))\n",
    "        (plot,) = ax.plot(x, data, animated=True, c=c)\n",
    "        return plot\n",
    "        \n",
    "    def update(self, user_pitch):\n",
    "        self.target_past = np.append(self.target_past[1:], [self.target_future[0]])\n",
    "        \n",
    "        if len(self.targ_pitch_queue): # at the end of song have no target pitch in queue\n",
    "            next_targ_pitch = self.targ_pitch_queue.pop(0)\n",
    "        else:\n",
    "            \n",
    "            next_targ_pitch = np.nan\n",
    "            \n",
    "        self.target_future = np.append(self.target_future[1:], [next_targ_pitch])\n",
    "                                     \n",
    "                                     \n",
    "        self.user_pitch_arr = np.append(self.user_pitch_arr[1:], [user_pitch])\n",
    "        self.mae_arr = np.append(self.mae_arr[1:], [self._calc_next_mae(self.target_past, self.user_pitch_arr)])\n",
    "        \n",
    "#         plotted_data.set_data(indexes[not_nan_mask], new_plot_data[not_nan_mask])\n",
    "        self.user_pitch_plot.set_ydata(np.concatenate([self.user_pitch_arr, self.user_pitch_padding]))\n",
    "        self.target_past_plot.set_ydata(self.target_past)\n",
    "        self.target_future_plot.set_ydata(self.target_future)\n",
    "        self.mae_plot.set_ydata(self.mae_arr)\n",
    "        \n",
    "        self._redraw_plot()\n",
    "        \n",
    "    def _calc_next_mae(self, targ, pred):\n",
    "        mae_arr1, mae_arr2 = targ[-1 * self.mae_npoints:], pred[-1 * self.mae_npoints:]\n",
    "        both_notnull_mask = (~np.isnan(mae_arr1)) & (~np.isnan(mae_arr2))\n",
    "        \n",
    "        mae_arr1 = mae_arr1[both_notnull_mask]\n",
    "        mae_arr2 = mae_arr2[both_notnull_mask]\n",
    "        if len(mae_arr1) == 0: # silence on intersection\n",
    "            value = np.nan\n",
    "        value = np.mean(np.abs(mae_arr1 - mae_arr2))\n",
    "        return value\n",
    "                                       \n",
    "    def _redraw_plot(self):\n",
    "        self.fig.canvas.restore_region(self._bg)\n",
    "        \n",
    "        for ax_name, ax_obj in self.axes.items(): \n",
    "            ax = ax_obj[\"ax\"]\n",
    "            for artist in ax_obj[\"artists\"]:\n",
    "                ax.draw_artist(artist)\n",
    "                             \n",
    "        # show the result to the screen, this pushes the updated RGBA buffer from the\n",
    "        # renderer to the GUI framework so you can see it\n",
    "        self.fig.canvas.blit(self.fig.bbox)\n",
    "        self.fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f22fd21-c65d-4dfb-9857-0332ef2ead79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_pitch_realtime(signal, model):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    frames = signal[:1024].reshape(1, -1)\n",
    "    frames -= np.mean(frames, axis=1)[:, np.newaxis]\n",
    "    frames /= np.std(frames, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    model_preds = model(frames, training=False)#, workers=-1, use_multiprocessing=True)\n",
    "    model_preds = model_preds.numpy()\n",
    "    \n",
    "    print(\"model preds sum\", model_preds.sum())\n",
    "    \n",
    "    too_low_too_high_mask = np.concatenate([[True] * 80 + [False] * 140 + [True] * 140])\n",
    "    model_preds[:, too_low_too_high_mask] = 0\n",
    "#     print(\"time needed\", time.time() - start_time)\n",
    "    batch_pitch = model_preds.argmax(axis=1)\n",
    "    confidence = model_preds.max(axis=1)\n",
    "    \n",
    "    return batch_pitch, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13346ee6-5681-455c-891d-b9744950dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song(f, mono=False):\n",
    "    \"\"\"MP3 to numpy array\"\"\"\n",
    "    a = AudioSegment.from_mp3(f)\n",
    "    y = np.array(a.get_array_of_samples())\n",
    "    if a.channels == 2:\n",
    "        y = y.reshape((-1, 2))\n",
    "        if mono:\n",
    "            y = y.mean(axis=1)\n",
    "    return y, a.frame_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e2ba88e-2b19-4aed-b0ec-282d7754188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import pygame\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "    \n",
    "\n",
    "class SongPlayer:\n",
    "    def __init__(self, song_pth, bounds):\n",
    "        print(\"bounds\", bounds)\n",
    "        target_pitch = songs_target_pitch[song_pth]\n",
    "        \n",
    "        tg_len = len(target_pitch)\n",
    "        start, end = bounds\n",
    "        # initially in range 0-100\n",
    "        start /= 100\n",
    "        end /= 100\n",
    "        \n",
    "        cropped_targ_pitch = target_pitch[int(start * tg_len): int(end * tg_len)]\n",
    "        \n",
    "        song_mono, srate = load_song(song_pth, mono=True)\n",
    "        print(\"src shape\", song_mono.shape, srate)\n",
    "        song_ln = len(song_mono)\n",
    "        cropped_song = song_mono[int(start * song_ln): int(end * song_ln)]\n",
    "        print(\"cropped\", cropped_song)\n",
    "        \n",
    "        self.song_pth = \"now_played_song.wav\"\n",
    "        write(self.song_pth, srate, cropped_song.astype(np.int16))\n",
    "        \n",
    "        AudioSegment.from_wav(self.song_pth).export('now_played_song.ogg', format='ogg')\n",
    "        \n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(\"now_played_song.ogg\")\n",
    "        \n",
    "        self.targ_pitch = cropped_targ_pitch\n",
    "        \n",
    "        self.stream = None\n",
    "        self.plotter = None\n",
    "        \n",
    "    def start(self):\n",
    "        self.stream = sd.InputStream(\n",
    "                        samplerate=MODEL_SR,\n",
    "                        blocksize = BLOCK_SIZE,\n",
    "                        channels = 1,\n",
    "        )\n",
    "        \n",
    "        self.plotter = Plotter(self.targ_pitch)\n",
    "        \n",
    "        self.stream.start()\n",
    "        pygame.mixer.music.play()\n",
    "        \n",
    "    def play(self):\n",
    "        for block_idx in range(len(self.targ_pitch)):\n",
    "            user_pitch = self._get_user_pitch()\n",
    "            self.plotter.update(user_pitch)\n",
    "            yield\n",
    "            \n",
    "        self.stop()\n",
    "        \n",
    "    def _get_user_pitch(self):  \n",
    "        audio_arr, is_overflowed = self.stream.read(BLOCK_SIZE)\n",
    "        if is_overflowed:\n",
    "            raise OverflowError()\n",
    "\n",
    "        model_preds, confidence = detect_pitch_realtime(audio_arr, pitch_model)\n",
    "        model_preds = model_preds.astype(np.float32)\n",
    "        model_preds[confidence < 0.5] = None\n",
    "        \n",
    "        assert len(model_preds) == 1\n",
    "        return model_preds[0]\n",
    "        \n",
    "    def stop(self):\n",
    "        pygame.mixer.music.stop()\n",
    "        self.stream.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3dac02-bd13-49ef-bfff-62ae634bba78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b53c33cf-58a9-4386-bc43-706899032a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fragment_bounds():\n",
    "    start = input(\"start percentile\\n\")\n",
    "    if len(start) == 0:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = int(start)\n",
    "    end = input(\"end percentile\\n\")\n",
    "    if len(end) == 0:\n",
    "        end = 100\n",
    "    else:\n",
    "        end = int(end)\n",
    "        \n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00cc1696-6b8d-4d2f-9b0e-5b6c4c5f2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_playing():\n",
    "    print(\"If move to next track, pass N\")\n",
    "    print(\"If repeat this track, pass R\")\n",
    "    print(\"If previous track, pass P\")\n",
    "    value = input()\n",
    "    return {\"N\": \"next\", \"R\": \"repeat\", \"P\": \"previous\"}[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4a86a-66c5-4bcb-a20a-dbfb91421c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c982d-3eec-4fcd-bafc-05019f0d7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_sound_pth = \"../data/samples/click.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d972cec-af30-4dc5-96a1-ca137b91cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# click = librosa.clicks(times=[0], click_duration=1, sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96960b2d-9dce-4ac4-b94b-dadd91a4f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(click, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45024a98-0a01-4426-ac9b-3d78b4863079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# scipy.io.wavfile.write(click_sound_pth, 44100, click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dd615-bde8-46bd-9fa0-9331f56eda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_countdown(n: int):\n",
    "    # TODO: add click sound\n",
    "    for num in range(n, 0, -1):\n",
    "        print(f\"Prepare: {num}\")\n",
    "        playsound.playsound(click_sound_pth, False)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67104f78-ab04-4ee1-a542-2f4ee975a42e",
   "metadata": {},
   "source": [
    "## TODO: STOP BUTTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710bc28-0309-42d0-aedb-bcb7152827ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_idx = 0\n",
    "\n",
    "next_play_name_to_idx_change = {\n",
    "    \"repeat\": 0,\n",
    "    \"next\": 1,\n",
    "    \"previous\": -1,\n",
    "}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "#         ipd.display(need_stop_widg)\n",
    "        # input to choose part of song to play\n",
    "        fragment_bounds = get_fragment_bounds()\n",
    "\n",
    "        player = SongPlayer(songs[song_idx], fragment_bounds)\n",
    "\n",
    "        do_countdown(3)\n",
    "        player.start()\n",
    "\n",
    "        for step in player.play():\n",
    "            ...\n",
    "            \n",
    "        next_playing = get_next_playing()\n",
    "        song_idx += next_play_name_to_idx_change[next_playing]\n",
    "        \n",
    "except BaseException as e:\n",
    "    pygame.mixer.music.stop()\n",
    "    plt.close(\"all\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd150f2-245c-4ad6-8647-f711a9efc9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d66cd-8b69-451a-b245-62010bdee4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dec1ca-c3c4-4159-b97d-b97137a0cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.query_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3687cc-0283-45e3-9907-8bdd3285e6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
