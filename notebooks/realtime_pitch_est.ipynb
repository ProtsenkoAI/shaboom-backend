{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e215c54b-5849-40eb-acb9-39c1d8032a99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TODO\n",
    "* add time-performance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f55a0a2-7789-4377-a4e6-f6d0bd3d724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 12:49:45.612180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-12 12:49:45.612214: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "import sounddevice as sd\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPool2D, Dropout, Permute, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb45db9-6908-4835-aa9a-d92d7c992f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SR = 16000\n",
    "# USE_CENTER_PAD = True\n",
    "\n",
    "# CALLS_PER_SEC = 2  # TODO: increase to 10-20 (should be smooth)\n",
    "# BLOCK_SIZE = MODEL_SR // CALLS_PER_SEC\n",
    "BLOCK_SIZE = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29233e4b-ecf4-451e-a5cc-b005d325a3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GTK3Agg',\n",
       " 'GTK3Cairo',\n",
       " 'MacOSX',\n",
       " 'nbAgg',\n",
       " 'Qt4Agg',\n",
       " 'Qt4Cairo',\n",
       " 'Qt5Agg',\n",
       " 'Qt5Cairo',\n",
       " 'TkAgg',\n",
       " 'TkCairo',\n",
       " 'WebAgg',\n",
       " 'WX',\n",
       " 'WXAgg',\n",
       " 'WXCairo',\n",
       " 'agg',\n",
       " 'cairo',\n",
       " 'pdf',\n",
       " 'pgf',\n",
       " 'ps',\n",
       " 'svg',\n",
       " 'template']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpl.rcsetup.all_backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdcdad49-1660-4f9a-ac8d-4664346ef783",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.use(\"Qt5Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae287db-7a30-4cd3-913f-9ca4519b2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_load_model(model_capacity, filename):\n",
    "    \"\"\"\n",
    "    Build the CNN model and load the weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_capacity : 'tiny', 'small', 'medium', 'large', or 'full'\n",
    "        String specifying the model capacity, which determines the model's\n",
    "        capacity multiplier to 4 (tiny), 8 (small), 16 (medium), 24 (large),\n",
    "        or 32 (full). 'full' uses the model size specified in the paper,\n",
    "        and the others use a reduced number of filters in each convolutional\n",
    "        layer, resulting in a smaller model that is faster to evaluate at the\n",
    "        cost of slightly reduced pitch estimation accuracy.\n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.keras.models.Model\n",
    "        The pre-trained keras model loaded in memory\n",
    "    \"\"\"\n",
    "\n",
    "    capacity_multiplier = {\n",
    "        'tiny': 4, 'small': 8, 'medium': 16, 'large': 24, 'full': 32\n",
    "    }[model_capacity]\n",
    "\n",
    "    layers = [1, 2, 3, 4, 5, 6]\n",
    "    filters = [n * capacity_multiplier for n in [32, 4, 4, 4, 8, 16]]\n",
    "    widths = [512, 64, 64, 64, 64, 64]\n",
    "    strides = [(4, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n",
    "\n",
    "    x = Input(shape=(1024,), name='input', dtype='float32')\n",
    "    y = Reshape(target_shape=(1024, 1, 1), name='input-reshape')(x)\n",
    "\n",
    "    for l, f, w, s in zip(layers, filters, widths, strides):\n",
    "        y = Conv2D(f, (w, 1), strides=s, padding='same',\n",
    "                   activation='relu', name=\"conv%d\" % l)(y)\n",
    "        y = BatchNormalization(name=\"conv%d-BN\" % l)(y)\n",
    "        y = MaxPool2D(pool_size=(2, 1), strides=None, padding='valid',\n",
    "                      name=\"conv%d-maxpool\" % l)(y)\n",
    "        y = Dropout(0.25, name=\"conv%d-dropout\" % l)(y)\n",
    "\n",
    "    y = Permute((2, 1, 3), name=\"transpose\")(y)\n",
    "    y = Flatten(name=\"flatten\")(y)\n",
    "    y = Dense(360, activation='sigmoid', name=\"classifier\")(y)\n",
    "\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "\n",
    "    model.load_weights(filename)\n",
    "    model.compile('adam', 'binary_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0348c0-7b40-49e4-82e3-34f00ae5002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 11:22:26.710123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-12 11:22:26.710166: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-12 11:22:26.710199: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gldsn-hw): /proc/driver/nvidia/version does not exist\n",
      "2021-08-12 11:22:26.710651: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = build_and_load_model(\"tiny\", \"../models/model-tiny.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4fa444-2219-4982-9cb8-04581fb29a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = sd.InputStream(\n",
    "                samplerate=MODEL_SR,\n",
    "                blocksize = 1024,\n",
    "                channels = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4bbd971-46f9-4aa4-ba51-e6c5c98705d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pitch_realtime(signal):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    frames = signal[:1024].reshape(1, -1)\n",
    "    frames -= np.mean(frames, axis=1)[:, np.newaxis]\n",
    "    frames /= np.std(frames, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    model_preds = model(frames, training=False)#, workers=-1, use_multiprocessing=True)\n",
    "    model_preds = model_preds.numpy()\n",
    "#     print(\"time needed\", time.time() - start_time)\n",
    "    batch_pitch = model_preds.argmax(axis=1)\n",
    "    confidence = model_preds.max(axis=1)\n",
    "    \n",
    "    return batch_pitch, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7631449-d4c5-4514-8734-95d8eb4a7ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECORD_SECONDS = 300\n",
    "stream.start()\n",
    "\n",
    "plt.ylim((60, 300))\n",
    "\n",
    "n_points = 200\n",
    "points = []\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# animated=True tells matplotlib to only draw the artist when we\n",
    "# explicitly request it\n",
    "(plotted_data,) = ax.plot(range(n_points), [60] * 100 + [300] * 100, animated=True)\n",
    "plt.show(block=False)\n",
    "plt.pause(0.1)\n",
    "\n",
    "bg = fig.canvas.copy_from_bbox(fig.bbox)\n",
    "# draw the animated artist, this uses a cached renderer\n",
    "ax.draw_artist(plotted_data)\n",
    "# show the result to the screen, this pushes the updated RGBA buffer from the\n",
    "# renderer to the GUI framework so you can see it\n",
    "fig.canvas.blit(fig.bbox)\n",
    "\n",
    "\n",
    "for block_idx in range(0, int(MODEL_SR / BLOCK_SIZE * RECORD_SECONDS)):\n",
    "    audio_arr, is_overflowed = stream.read(BLOCK_SIZE)\n",
    "#     if block_idx % 2 == 0:\n",
    "    if True:\n",
    "        if is_overflowed:\n",
    "            raise OverflowError()\n",
    "\n",
    "        model_preds, confidence = detect_pitch_realtime(audio_arr)\n",
    "        model_preds = model_preds.astype(np.float32)\n",
    "        model_preds[confidence < 0.5] = None\n",
    "        points += list(model_preds)\n",
    "\n",
    "    else:\n",
    "        points.append(np.nan)\n",
    "        \n",
    "    if len(points) >= n_points and len(points) % 1 == 0:\n",
    "#         display.clear_output(wait=True)\n",
    "#         plt.clf()\n",
    "    \n",
    "        fig.canvas.restore_region(bg)\n",
    "\n",
    "#         plt.scatter(range(n_points), points[-1 * n_points:])\n",
    "        \n",
    "        new_plot_data = np.array(points[-1 * n_points:])\n",
    "        not_nan_mask = np.logical_not(np.isnan(new_plot_data))\n",
    "        indexes = np.arange(len(new_plot_data))\n",
    "#         plotted_data.set_data(indexes[not_nan_mask], new_plot_data[not_nan_mask])\n",
    "        plotted_data.set_data(indexes, new_plot_data)\n",
    "#         plt.draw()\n",
    "#         plt.pause(1e-17)\n",
    "\n",
    "        ax.draw_artist(plotted_data)\n",
    "        fig.canvas.blit(fig.bbox)\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "#         display.display(plt.gcf())\n",
    "    \n",
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32641fa3-e973-414e-8f5b-4f6635ccacef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.query_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5751de-c1b5-4e96-847e-d3b6c7fe19ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
